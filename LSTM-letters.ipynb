{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The tutorial is here https://adventuresinmachinelearning.com/keras-lstm-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "\n",
    "\n",
    "import collections\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/amplifier/home/NEW_DL/LSTM/'\n",
    "\n",
    "def read_words(filename):\n",
    "    with tf.gfile.GFile(filename, \"r\") as f:\n",
    "        return f.read().replace(\"\\n\", \"\")\n",
    "\n",
    "def preproc(data):\n",
    "    new_dat = data.replace('<unk> ', '')\n",
    "    new_dat = new_dat.replace('\\'s ', '')\n",
    "    new_dat = new_dat.replace('\\'ve ', '')\n",
    "    new_dat = new_dat.replace('N ', '')\n",
    "    new_dat = new_dat.replace('N ', '')\n",
    "    new_dat = new_dat.translate({ord(c): None for c in '1234567890/-.*\\\\&!@#$\\''})\n",
    "    return new_dat\n",
    "\n",
    "def build_vocab(data):\n",
    "    a = set(new_dat) # get unique characters in string\n",
    "    a = list(a)      # convert to list\n",
    "    a.sort()         # sort inplace\n",
    "    d = {v:k for k,v in enumerate(a)} # make an ordered list (dictionary) from a\n",
    "    return d\n",
    "\n",
    "def get_str(string, length, batch_size):\n",
    "    \"\"\"\n",
    "    This class generates batches of set size at set skip_step INSTEAD OF creating an ENOROMOUS list or array of text\n",
    "    fragments that would hog the entire memory. You don't have to create the entire tensor (array, list) up front, but\n",
    "    can use a Generator object using 'yield' (see https://stackoverflow.com/questions/231767/what-does-the-yield-keyword-do)\n",
    "    that create the needed things on the fly.\n",
    "    \"\"\"\n",
    "    X = np.zeros((batch_size, length), dtype='uint8')\n",
    "    Y = np.zeros((batch_size, length, len(d)), dtype='uint8')\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            start = np.random.choice(len(string) - length)\n",
    "            end = start + length\n",
    "            if end >= len(string):\n",
    "                pass\n",
    "            x = string[start:end]\n",
    "            y = string[start+1:end+1]\n",
    "            X[i,:] = np.array([d[j] for j in x]).flatten()\n",
    "            one_hot = to_categorical(np.array([d[j] for j in y]).flatten(), len(d))\n",
    "            Y[i,:,:] = one_hot\n",
    "        yield X, Y\n",
    "        \n",
    "valid_data = read_words(data_path + 'ptb.valid.txt')\n",
    "valid_data = preproc(data)\n",
    "\n",
    "train_data = read_words(data_path + 'ptb.train.txt')\n",
    "train_data = preproc(data)\n",
    "\n",
    "d = build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "num_steps = 10\n",
    "train_data_generator = get_str(train_data, num_steps, batch_size)\n",
    "validation_data_generator = get_str(valid_data, num_steps, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 10, 100)           2700      \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 10, 100)           80400     \n",
      "_________________________________________________________________\n",
      "lstm_14 (LSTM)               (None, 10, 100)           80400     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 10, 100)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 10, 27)            2727      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10, 27)            0         \n",
      "=================================================================\n",
      "Total params: 166,227\n",
      "Trainable params: 166,227\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Embedding, Dropout, TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "\n",
    "hidden_size = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(d), hidden_size, input_length=num_steps))\n",
    "model.add(LSTM(hidden_size, return_sequences=True))\n",
    "model.add(LSTM(hidden_size, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(TimeDistributed(Dense(len(d))))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "72/72 [==============================] - 7s 96ms/step - loss: 2.9978 - categorical_accuracy: 0.1812 - val_loss: 2.8538 - val_categorical_accuracy: 0.1830\n",
      "Epoch 2/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 2.7402 - categorical_accuracy: 0.2031 - val_loss: 2.5878 - val_categorical_accuracy: 0.2379\n",
      "Epoch 3/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 2.4733 - categorical_accuracy: 0.2633 - val_loss: 2.3838 - val_categorical_accuracy: 0.2793\n",
      "Epoch 4/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 2.3393 - categorical_accuracy: 0.2970 - val_loss: 2.2736 - val_categorical_accuracy: 0.3165\n",
      "Epoch 5/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 2.2470 - categorical_accuracy: 0.3245 - val_loss: 2.1794 - val_categorical_accuracy: 0.3441\n",
      "Epoch 6/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 2.1605 - categorical_accuracy: 0.3491 - val_loss: 2.1105 - val_categorical_accuracy: 0.3670\n",
      "Epoch 7/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 2.1026 - categorical_accuracy: 0.3672 - val_loss: 2.0564 - val_categorical_accuracy: 0.3841\n",
      "Epoch 8/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 2.0494 - categorical_accuracy: 0.3827 - val_loss: 2.0060 - val_categorical_accuracy: 0.3964\n",
      "Epoch 9/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 2.0041 - categorical_accuracy: 0.3958 - val_loss: 1.9647 - val_categorical_accuracy: 0.4092\n",
      "Epoch 10/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.9687 - categorical_accuracy: 0.4056 - val_loss: 1.9242 - val_categorical_accuracy: 0.4177\n",
      "Epoch 11/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.9388 - categorical_accuracy: 0.4120 - val_loss: 1.8983 - val_categorical_accuracy: 0.4259\n",
      "Epoch 12/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.9047 - categorical_accuracy: 0.4228 - val_loss: 1.8713 - val_categorical_accuracy: 0.4353\n",
      "Epoch 13/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.8769 - categorical_accuracy: 0.4298 - val_loss: 1.8407 - val_categorical_accuracy: 0.4416\n",
      "Epoch 14/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.8530 - categorical_accuracy: 0.4367 - val_loss: 1.8105 - val_categorical_accuracy: 0.4514\n",
      "Epoch 15/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.8282 - categorical_accuracy: 0.4444 - val_loss: 1.7948 - val_categorical_accuracy: 0.4546\n",
      "Epoch 16/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.8132 - categorical_accuracy: 0.4472 - val_loss: 1.7795 - val_categorical_accuracy: 0.4598\n",
      "Epoch 17/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.7924 - categorical_accuracy: 0.4527 - val_loss: 1.7618 - val_categorical_accuracy: 0.4626\n",
      "Epoch 18/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.7768 - categorical_accuracy: 0.4567 - val_loss: 1.7393 - val_categorical_accuracy: 0.4703\n",
      "Epoch 19/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 1.7601 - categorical_accuracy: 0.4611 - val_loss: 1.7287 - val_categorical_accuracy: 0.4725\n",
      "Epoch 20/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.7466 - categorical_accuracy: 0.4654 - val_loss: 1.7089 - val_categorical_accuracy: 0.4790\n",
      "Epoch 21/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.7329 - categorical_accuracy: 0.4677 - val_loss: 1.7056 - val_categorical_accuracy: 0.4781\n",
      "Epoch 22/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.7238 - categorical_accuracy: 0.4713 - val_loss: 1.6901 - val_categorical_accuracy: 0.4824\n",
      "Epoch 23/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.7125 - categorical_accuracy: 0.4750 - val_loss: 1.6800 - val_categorical_accuracy: 0.4853\n",
      "Epoch 24/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.7047 - categorical_accuracy: 0.4772 - val_loss: 1.6650 - val_categorical_accuracy: 0.4897\n",
      "Epoch 25/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.6903 - categorical_accuracy: 0.4818 - val_loss: 1.6617 - val_categorical_accuracy: 0.4902\n",
      "Epoch 26/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.6830 - categorical_accuracy: 0.4824 - val_loss: 1.6451 - val_categorical_accuracy: 0.4950\n",
      "Epoch 27/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.6783 - categorical_accuracy: 0.4846 - val_loss: 1.6449 - val_categorical_accuracy: 0.4941\n",
      "Epoch 28/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.6703 - categorical_accuracy: 0.4852 - val_loss: 1.6421 - val_categorical_accuracy: 0.4965\n",
      "Epoch 29/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 1.6607 - categorical_accuracy: 0.4890 - val_loss: 1.6281 - val_categorical_accuracy: 0.4998\n",
      "Epoch 30/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.6547 - categorical_accuracy: 0.4888 - val_loss: 1.6243 - val_categorical_accuracy: 0.5001\n",
      "Epoch 31/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.6535 - categorical_accuracy: 0.4889 - val_loss: 1.6134 - val_categorical_accuracy: 0.5031\n",
      "Epoch 32/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.6430 - categorical_accuracy: 0.4927 - val_loss: 1.6050 - val_categorical_accuracy: 0.5051\n",
      "Epoch 33/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.6321 - categorical_accuracy: 0.4956 - val_loss: 1.6135 - val_categorical_accuracy: 0.5038\n",
      "Epoch 34/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.6356 - categorical_accuracy: 0.4946 - val_loss: 1.5986 - val_categorical_accuracy: 0.5073\n",
      "Epoch 35/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.6296 - categorical_accuracy: 0.4971 - val_loss: 1.5951 - val_categorical_accuracy: 0.5082\n",
      "Epoch 36/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 1.6182 - categorical_accuracy: 0.4999 - val_loss: 1.5850 - val_categorical_accuracy: 0.5103\n",
      "Epoch 37/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.6184 - categorical_accuracy: 0.4991 - val_loss: 1.5799 - val_categorical_accuracy: 0.5120\n",
      "Epoch 38/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.6120 - categorical_accuracy: 0.5013 - val_loss: 1.5751 - val_categorical_accuracy: 0.5142\n",
      "Epoch 39/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.6116 - categorical_accuracy: 0.5018 - val_loss: 1.5705 - val_categorical_accuracy: 0.5134\n",
      "Epoch 40/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.6014 - categorical_accuracy: 0.5034 - val_loss: 1.5684 - val_categorical_accuracy: 0.5145\n",
      "Epoch 41/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5991 - categorical_accuracy: 0.5043 - val_loss: 1.5792 - val_categorical_accuracy: 0.5119\n",
      "Epoch 42/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5930 - categorical_accuracy: 0.5060 - val_loss: 1.5634 - val_categorical_accuracy: 0.5171\n",
      "Epoch 43/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5972 - categorical_accuracy: 0.5051 - val_loss: 1.5557 - val_categorical_accuracy: 0.5174\n",
      "Epoch 44/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.5875 - categorical_accuracy: 0.5079 - val_loss: 1.5585 - val_categorical_accuracy: 0.5166\n",
      "Epoch 45/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5807 - categorical_accuracy: 0.5090 - val_loss: 1.5483 - val_categorical_accuracy: 0.5186\n",
      "Epoch 46/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5813 - categorical_accuracy: 0.5082 - val_loss: 1.5502 - val_categorical_accuracy: 0.5180\n",
      "Epoch 47/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5795 - categorical_accuracy: 0.5094 - val_loss: 1.5467 - val_categorical_accuracy: 0.5182\n",
      "Epoch 48/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 1.5747 - categorical_accuracy: 0.5112 - val_loss: 1.5485 - val_categorical_accuracy: 0.5195\n",
      "Epoch 49/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5710 - categorical_accuracy: 0.5111 - val_loss: 1.5388 - val_categorical_accuracy: 0.5216\n",
      "Epoch 50/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5690 - categorical_accuracy: 0.5115 - val_loss: 1.5385 - val_categorical_accuracy: 0.5217\n",
      "Epoch 51/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5666 - categorical_accuracy: 0.5123 - val_loss: 1.5326 - val_categorical_accuracy: 0.5223\n",
      "Epoch 52/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 1.5678 - categorical_accuracy: 0.5122 - val_loss: 1.5258 - val_categorical_accuracy: 0.5259\n",
      "Epoch 53/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5626 - categorical_accuracy: 0.5135 - val_loss: 1.5281 - val_categorical_accuracy: 0.5245\n",
      "Epoch 54/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5599 - categorical_accuracy: 0.5146 - val_loss: 1.5222 - val_categorical_accuracy: 0.5264\n",
      "Epoch 55/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5606 - categorical_accuracy: 0.5132 - val_loss: 1.5317 - val_categorical_accuracy: 0.5239\n",
      "Epoch 56/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5557 - categorical_accuracy: 0.5149 - val_loss: 1.5176 - val_categorical_accuracy: 0.5272\n",
      "Epoch 57/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5558 - categorical_accuracy: 0.5151 - val_loss: 1.5179 - val_categorical_accuracy: 0.5264\n",
      "Epoch 58/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5480 - categorical_accuracy: 0.5175 - val_loss: 1.5139 - val_categorical_accuracy: 0.5274\n",
      "Epoch 59/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5509 - categorical_accuracy: 0.5162 - val_loss: 1.5151 - val_categorical_accuracy: 0.5280\n",
      "Epoch 60/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5467 - categorical_accuracy: 0.5170 - val_loss: 1.5153 - val_categorical_accuracy: 0.5281\n",
      "Epoch 61/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5456 - categorical_accuracy: 0.5170 - val_loss: 1.5092 - val_categorical_accuracy: 0.5284\n",
      "Epoch 62/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5441 - categorical_accuracy: 0.5183 - val_loss: 1.5137 - val_categorical_accuracy: 0.5278\n",
      "Epoch 63/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5383 - categorical_accuracy: 0.5190 - val_loss: 1.5124 - val_categorical_accuracy: 0.5285\n",
      "Epoch 64/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5387 - categorical_accuracy: 0.5199 - val_loss: 1.5122 - val_categorical_accuracy: 0.5293\n",
      "Epoch 65/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5353 - categorical_accuracy: 0.5195 - val_loss: 1.5080 - val_categorical_accuracy: 0.5308\n",
      "Epoch 66/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5333 - categorical_accuracy: 0.5218 - val_loss: 1.5053 - val_categorical_accuracy: 0.5294\n",
      "Epoch 67/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5390 - categorical_accuracy: 0.5189 - val_loss: 1.4967 - val_categorical_accuracy: 0.5312\n",
      "Epoch 68/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5317 - categorical_accuracy: 0.5205 - val_loss: 1.4944 - val_categorical_accuracy: 0.5335\n",
      "Epoch 69/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5311 - categorical_accuracy: 0.5214 - val_loss: 1.4935 - val_categorical_accuracy: 0.5330\n",
      "Epoch 70/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.5268 - categorical_accuracy: 0.5218 - val_loss: 1.4967 - val_categorical_accuracy: 0.5317\n",
      "Epoch 71/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.5294 - categorical_accuracy: 0.5221 - val_loss: 1.4863 - val_categorical_accuracy: 0.5349\n",
      "Epoch 72/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5230 - categorical_accuracy: 0.5241 - val_loss: 1.4894 - val_categorical_accuracy: 0.5341\n",
      "Epoch 73/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5204 - categorical_accuracy: 0.5240 - val_loss: 1.4963 - val_categorical_accuracy: 0.5324\n",
      "Epoch 74/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5209 - categorical_accuracy: 0.5229 - val_loss: 1.4913 - val_categorical_accuracy: 0.5327\n",
      "Epoch 75/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5208 - categorical_accuracy: 0.5244 - val_loss: 1.4899 - val_categorical_accuracy: 0.5334\n",
      "Epoch 76/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5234 - categorical_accuracy: 0.5215 - val_loss: 1.4839 - val_categorical_accuracy: 0.5352\n",
      "Epoch 77/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5205 - categorical_accuracy: 0.5234 - val_loss: 1.4840 - val_categorical_accuracy: 0.5346\n",
      "Epoch 78/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 1.5168 - categorical_accuracy: 0.5251 - val_loss: 1.4895 - val_categorical_accuracy: 0.5340\n",
      "Epoch 79/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5129 - categorical_accuracy: 0.5265 - val_loss: 1.4782 - val_categorical_accuracy: 0.5361\n",
      "Epoch 80/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5128 - categorical_accuracy: 0.5261 - val_loss: 1.4831 - val_categorical_accuracy: 0.5364\n",
      "Epoch 81/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5087 - categorical_accuracy: 0.5272 - val_loss: 1.4782 - val_categorical_accuracy: 0.5364\n",
      "Epoch 82/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5077 - categorical_accuracy: 0.5272 - val_loss: 1.4759 - val_categorical_accuracy: 0.5363\n",
      "Epoch 83/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5060 - categorical_accuracy: 0.5284 - val_loss: 1.4747 - val_categorical_accuracy: 0.5372\n",
      "Epoch 84/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5129 - categorical_accuracy: 0.5250 - val_loss: 1.4876 - val_categorical_accuracy: 0.5367\n",
      "Epoch 85/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5050 - categorical_accuracy: 0.5285 - val_loss: 1.4744 - val_categorical_accuracy: 0.5362\n",
      "Epoch 86/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5061 - categorical_accuracy: 0.5270 - val_loss: 1.4732 - val_categorical_accuracy: 0.5385\n",
      "Epoch 87/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5039 - categorical_accuracy: 0.5288 - val_loss: 1.4686 - val_categorical_accuracy: 0.5388\n",
      "Epoch 88/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5037 - categorical_accuracy: 0.5281 - val_loss: 1.4774 - val_categorical_accuracy: 0.5366\n",
      "Epoch 89/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5011 - categorical_accuracy: 0.5288 - val_loss: 1.4703 - val_categorical_accuracy: 0.5394\n",
      "Epoch 90/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.5020 - categorical_accuracy: 0.5291 - val_loss: 1.4736 - val_categorical_accuracy: 0.5381\n",
      "Epoch 91/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4973 - categorical_accuracy: 0.5298 - val_loss: 1.4781 - val_categorical_accuracy: 0.5378\n",
      "Epoch 92/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.5017 - categorical_accuracy: 0.5281 - val_loss: 1.4672 - val_categorical_accuracy: 0.5392\n",
      "Epoch 93/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4992 - categorical_accuracy: 0.5290 - val_loss: 1.4672 - val_categorical_accuracy: 0.5390\n",
      "Epoch 94/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4962 - categorical_accuracy: 0.5298 - val_loss: 1.4582 - val_categorical_accuracy: 0.5418\n",
      "Epoch 95/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.4983 - categorical_accuracy: 0.5287 - val_loss: 1.4605 - val_categorical_accuracy: 0.5405\n",
      "Epoch 96/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4969 - categorical_accuracy: 0.5294 - val_loss: 1.4592 - val_categorical_accuracy: 0.5421\n",
      "Epoch 97/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4918 - categorical_accuracy: 0.5320 - val_loss: 1.4611 - val_categorical_accuracy: 0.5410\n",
      "Epoch 98/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4921 - categorical_accuracy: 0.5301 - val_loss: 1.4636 - val_categorical_accuracy: 0.5414\n",
      "Epoch 99/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4920 - categorical_accuracy: 0.5319 - val_loss: 1.4644 - val_categorical_accuracy: 0.5411\n",
      "Epoch 100/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 1.4962 - categorical_accuracy: 0.5295 - val_loss: 1.4622 - val_categorical_accuracy: 0.5406\n",
      "Epoch 101/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4891 - categorical_accuracy: 0.5310 - val_loss: 1.4581 - val_categorical_accuracy: 0.5418\n",
      "Epoch 102/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4913 - categorical_accuracy: 0.5309 - val_loss: 1.4570 - val_categorical_accuracy: 0.5415\n",
      "Epoch 103/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4884 - categorical_accuracy: 0.5306 - val_loss: 1.4633 - val_categorical_accuracy: 0.5411\n",
      "Epoch 104/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 1.4932 - categorical_accuracy: 0.5290 - val_loss: 1.4622 - val_categorical_accuracy: 0.5410\n",
      "Epoch 105/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4899 - categorical_accuracy: 0.5321 - val_loss: 1.4582 - val_categorical_accuracy: 0.5420\n",
      "Epoch 106/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 1.4832 - categorical_accuracy: 0.5343 - val_loss: 1.4523 - val_categorical_accuracy: 0.5435\n",
      "Epoch 107/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.4883 - categorical_accuracy: 0.5322 - val_loss: 1.4536 - val_categorical_accuracy: 0.5416\n",
      "Epoch 108/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4884 - categorical_accuracy: 0.5323 - val_loss: 1.4543 - val_categorical_accuracy: 0.5418\n",
      "Epoch 109/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4875 - categorical_accuracy: 0.5307 - val_loss: 1.4481 - val_categorical_accuracy: 0.5443\n",
      "Epoch 110/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4808 - categorical_accuracy: 0.5336 - val_loss: 1.4472 - val_categorical_accuracy: 0.5438\n",
      "Epoch 111/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4835 - categorical_accuracy: 0.5330 - val_loss: 1.4551 - val_categorical_accuracy: 0.5438\n",
      "Epoch 112/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 1.4855 - categorical_accuracy: 0.5335 - val_loss: 1.4575 - val_categorical_accuracy: 0.5430\n",
      "Epoch 113/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4786 - categorical_accuracy: 0.5347 - val_loss: 1.4456 - val_categorical_accuracy: 0.5452\n",
      "Epoch 114/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.4765 - categorical_accuracy: 0.5350 - val_loss: 1.4543 - val_categorical_accuracy: 0.5422\n",
      "Epoch 115/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4819 - categorical_accuracy: 0.5334 - val_loss: 1.4431 - val_categorical_accuracy: 0.5442\n",
      "Epoch 116/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4764 - categorical_accuracy: 0.5347 - val_loss: 1.4412 - val_categorical_accuracy: 0.5475\n",
      "Epoch 117/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.4773 - categorical_accuracy: 0.5353 - val_loss: 1.4469 - val_categorical_accuracy: 0.5450\n",
      "Epoch 118/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4742 - categorical_accuracy: 0.5356 - val_loss: 1.4432 - val_categorical_accuracy: 0.5442\n",
      "Epoch 119/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4759 - categorical_accuracy: 0.5338 - val_loss: 1.4486 - val_categorical_accuracy: 0.5446\n",
      "Epoch 120/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4710 - categorical_accuracy: 0.5368 - val_loss: 1.4474 - val_categorical_accuracy: 0.5432\n",
      "Epoch 121/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4759 - categorical_accuracy: 0.5354 - val_loss: 1.4419 - val_categorical_accuracy: 0.5449\n",
      "Epoch 122/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4746 - categorical_accuracy: 0.5354 - val_loss: 1.4475 - val_categorical_accuracy: 0.5440\n",
      "Epoch 123/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4697 - categorical_accuracy: 0.5366 - val_loss: 1.4422 - val_categorical_accuracy: 0.5464\n",
      "Epoch 124/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4764 - categorical_accuracy: 0.5343 - val_loss: 1.4380 - val_categorical_accuracy: 0.5474\n",
      "Epoch 125/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4709 - categorical_accuracy: 0.5365 - val_loss: 1.4413 - val_categorical_accuracy: 0.5482\n",
      "Epoch 126/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4662 - categorical_accuracy: 0.5378 - val_loss: 1.4399 - val_categorical_accuracy: 0.5464\n",
      "Epoch 127/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4708 - categorical_accuracy: 0.5358 - val_loss: 1.4335 - val_categorical_accuracy: 0.5480\n",
      "Epoch 128/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4693 - categorical_accuracy: 0.5365 - val_loss: 1.4418 - val_categorical_accuracy: 0.5470\n",
      "Epoch 129/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4660 - categorical_accuracy: 0.5373 - val_loss: 1.4412 - val_categorical_accuracy: 0.5457\n",
      "Epoch 130/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4749 - categorical_accuracy: 0.5357 - val_loss: 1.4460 - val_categorical_accuracy: 0.5452\n",
      "Epoch 131/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4664 - categorical_accuracy: 0.5371 - val_loss: 1.4335 - val_categorical_accuracy: 0.5488\n",
      "Epoch 132/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4664 - categorical_accuracy: 0.5383 - val_loss: 1.4319 - val_categorical_accuracy: 0.5487\n",
      "Epoch 133/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4653 - categorical_accuracy: 0.5384 - val_loss: 1.4335 - val_categorical_accuracy: 0.5480\n",
      "Epoch 134/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4647 - categorical_accuracy: 0.5364 - val_loss: 1.4426 - val_categorical_accuracy: 0.5475\n",
      "Epoch 135/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4668 - categorical_accuracy: 0.5368 - val_loss: 1.4337 - val_categorical_accuracy: 0.5463\n",
      "Epoch 136/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4603 - categorical_accuracy: 0.5383 - val_loss: 1.4330 - val_categorical_accuracy: 0.5481\n",
      "Epoch 137/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4614 - categorical_accuracy: 0.5392 - val_loss: 1.4322 - val_categorical_accuracy: 0.5478\n",
      "Epoch 138/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4643 - categorical_accuracy: 0.5386 - val_loss: 1.4342 - val_categorical_accuracy: 0.5480\n",
      "Epoch 139/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4609 - categorical_accuracy: 0.5387 - val_loss: 1.4308 - val_categorical_accuracy: 0.5476\n",
      "Epoch 140/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4620 - categorical_accuracy: 0.5393 - val_loss: 1.4320 - val_categorical_accuracy: 0.5478\n",
      "Epoch 141/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4610 - categorical_accuracy: 0.5396 - val_loss: 1.4285 - val_categorical_accuracy: 0.5488\n",
      "Epoch 142/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4597 - categorical_accuracy: 0.5399 - val_loss: 1.4327 - val_categorical_accuracy: 0.5489\n",
      "Epoch 143/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4584 - categorical_accuracy: 0.5398 - val_loss: 1.4352 - val_categorical_accuracy: 0.5478\n",
      "Epoch 144/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4632 - categorical_accuracy: 0.5394 - val_loss: 1.4256 - val_categorical_accuracy: 0.5507\n",
      "Epoch 145/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4621 - categorical_accuracy: 0.5373 - val_loss: 1.4349 - val_categorical_accuracy: 0.5498\n",
      "Epoch 146/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4592 - categorical_accuracy: 0.5391 - val_loss: 1.4253 - val_categorical_accuracy: 0.5511\n",
      "Epoch 147/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4577 - categorical_accuracy: 0.5388 - val_loss: 1.4269 - val_categorical_accuracy: 0.5499\n",
      "Epoch 148/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4566 - categorical_accuracy: 0.5402 - val_loss: 1.4251 - val_categorical_accuracy: 0.5508\n",
      "Epoch 149/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.4565 - categorical_accuracy: 0.5405 - val_loss: 1.4392 - val_categorical_accuracy: 0.5476\n",
      "Epoch 150/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 1.4531 - categorical_accuracy: 0.5407 - val_loss: 1.4236 - val_categorical_accuracy: 0.5499\n",
      "Epoch 151/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 1.4537 - categorical_accuracy: 0.5409 - val_loss: 1.4229 - val_categorical_accuracy: 0.5517\n",
      "Epoch 152/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4530 - categorical_accuracy: 0.5414 - val_loss: 1.4263 - val_categorical_accuracy: 0.5494\n",
      "Epoch 153/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4536 - categorical_accuracy: 0.5415 - val_loss: 1.4270 - val_categorical_accuracy: 0.5513\n",
      "Epoch 154/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4543 - categorical_accuracy: 0.5413 - val_loss: 1.4231 - val_categorical_accuracy: 0.5513\n",
      "Epoch 155/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4529 - categorical_accuracy: 0.5410 - val_loss: 1.4233 - val_categorical_accuracy: 0.5513\n",
      "Epoch 156/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4519 - categorical_accuracy: 0.5415 - val_loss: 1.4314 - val_categorical_accuracy: 0.5505\n",
      "Epoch 157/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4553 - categorical_accuracy: 0.5401 - val_loss: 1.4197 - val_categorical_accuracy: 0.5512\n",
      "Epoch 158/400\n",
      "72/72 [==============================] - 4s 55ms/step - loss: 1.4543 - categorical_accuracy: 0.5407 - val_loss: 1.4246 - val_categorical_accuracy: 0.5508\n",
      "Epoch 159/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4529 - categorical_accuracy: 0.5419 - val_loss: 1.4263 - val_categorical_accuracy: 0.5498\n",
      "Epoch 160/400\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 1.4525 - categorical_accuracy: 0.5410 - val_loss: 1.4186 - val_categorical_accuracy: 0.5514\n",
      "Epoch 161/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4529 - categorical_accuracy: 0.5405 - val_loss: 1.4227 - val_categorical_accuracy: 0.5503\n",
      "Epoch 162/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4519 - categorical_accuracy: 0.5411 - val_loss: 1.4222 - val_categorical_accuracy: 0.5509\n",
      "Epoch 163/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4539 - categorical_accuracy: 0.5405 - val_loss: 1.4175 - val_categorical_accuracy: 0.5522\n",
      "Epoch 164/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4498 - categorical_accuracy: 0.5416 - val_loss: 1.4210 - val_categorical_accuracy: 0.5498\n",
      "Epoch 165/400\n",
      "72/72 [==============================] - 4s 54ms/step - loss: 1.4513 - categorical_accuracy: 0.5416 - val_loss: 1.4170 - val_categorical_accuracy: 0.5526\n",
      "Epoch 166/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4498 - categorical_accuracy: 0.5416 - val_loss: 1.4158 - val_categorical_accuracy: 0.5522\n",
      "Epoch 167/400\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4498 - categorical_accuracy: 0.5420 - val_loss: 1.4158 - val_categorical_accuracy: 0.5521\n",
      "Epoch 168/400\n",
      "53/72 [=====================>........] - ETA: 0s - loss: 1.4449 - categorical_accuracy: 0.5428"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-96cca824fd33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                    )\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 400\n",
    "checkpointer = ModelCheckpoint(filepath=data_path + 'model-{epoch:02d}.hdf5', verbose=1)\n",
    "csv_logger = CSVLogger('log.csv', append=True, separator=',')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
    "model.fit_generator(train_data_generator,\n",
    "                    len(train_data)//(batch_size*num_steps),\n",
    "                    num_epochs,\n",
    "                    validation_data=validation_data_generator,\n",
    "                    validation_steps=len(valid_data)//(batch_size*num_steps)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14  0 20 20  0 20  8  5  0 19]\n",
      "['n', ' ', 't', 't', ' ', 't', 'h', 'e', ' ', 's']\n"
     ]
    }
   ],
   "source": [
    "rev_d = {k:v for k,v in enumerate(d)}\n",
    "tst = np.array([d[j] for j in 'at is the ']).reshape(1,10)\n",
    "pred = np.argmax(model.predict(tst).reshape(10,27), axis=1)\n",
    "print(pred)\n",
    "print([rev_d[i] for i in pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' ',\n",
       " 1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z'}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
