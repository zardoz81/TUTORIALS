{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import gym\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to convert numpy arrays to tensors\n",
    "def t(x): \n",
    "    return torch.from_numpy(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actor module, categorical actions only\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_dim, n_actions):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(state_dim, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(32, n_actions),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "\n",
    "    \n",
    "    \n",
    "# Critic module\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(state_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "# env = gym.make(\"LunarLander-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "state space dim: 4\naction space dim: 2\n"
    }
   ],
   "source": [
    "# config\n",
    "state_dim = env.observation_space.shape[0]\n",
    "print('state space dim: {}'.format(state_dim))\n",
    "n_actions = env.action_space.n\n",
    "print('action space dim: {}'.format(n_actions))\n",
    "actor = Actor(state_dim, n_actions)\n",
    "critic = Critic(state_dim)\n",
    "adam_actor = torch.optim.Adam(actor.parameters(), lr=1e-3)\n",
    "adam_critic = torch.optim.Adam(critic.parameters(), lr=1e-3)\n",
    "gamma = 0.99\n",
    "\n",
    "# actor.load_state_dict(torch.load('./actor_{}.pth'.format('LunarLander'), map_location=torch.device('cpu')))\n",
    "# critic.load_state_dict(torch.load('./critic_{}.pth'.format('LunarLander'), map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the vanilla policy gradient method:\n",
    "\n",
    "$$ \\nabla_\\theta J(\\theta) = \\frac{1}{N} \\sum^{N}_{i=1} \\sum^{T}_{t=1} \\nabla_\\theta\\log\\pi_\\theta(a_{i,t}|s_{i,t})\\Bigg(\\sum^{T}_{t^\\prime=1}r(a_{i,t}|s_{i,t})\\Bigg) $$\n",
    "\n",
    "\n",
    "by definition, $$ Q_w(s_t, a_t) = r_{t+1} + V(s_{t+1})$$\n",
    "is the total reward expected if action $a$ is taken in state $s$ at time $t$. One term of this equation is already \"known\", because given a state and an action at time $t$, the reward is determined by the environment.\n",
    "\n",
    "$V(s_{t+1})$ is pretty uncertain (we don't know the actions yet, hence don't know the rewards). In other words, we can _estimate_ $V(s)$ because the actions are unknown yet.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Episode: 0\t RWD: 21.00\t TCL: 20.91\t TAL: 14.74\t elapsed 0.06 s.\nEpisode: 1\t RWD: 16.00\t TCL: 15.72\t TAL: 10.95\t elapsed 0.03 s.\nEpisode: 2\t RWD: 20.00\t TCL: 19.70\t TAL: 13.21\t elapsed 0.03 s.\nEpisode: 3\t RWD: 21.00\t TCL: 20.61\t TAL: 15.39\t elapsed 0.03 s.\nEpisode: 4\t RWD: 43.00\t TCL: 42.44\t TAL: 30.87\t elapsed 0.07 s.\nEpisode: 5\t RWD: 16.00\t TCL: 15.46\t TAL: 10.77\t elapsed 0.02 s.\nEpisode: 6\t RWD: 12.00\t TCL: 11.43\t TAL: 8.16\t elapsed 0.02 s.\nEpisode: 7\t RWD: 13.00\t TCL: 12.34\t TAL: 8.03\t elapsed 0.03 s.\nEpisode: 8\t RWD: 20.00\t TCL: 19.15\t TAL: 13.24\t elapsed 0.04 s.\nEpisode: 9\t RWD: 14.00\t TCL: 13.11\t TAL: 9.04\t elapsed 0.02 s.\nEpisode: 10\t RWD: 16.00\t TCL: 14.97\t TAL: 10.24\t elapsed 0.03 s.\nEpisode: 11\t RWD: 15.00\t TCL: 13.89\t TAL: 9.25\t elapsed 0.02 s.\nEpisode: 12\t RWD: 21.00\t TCL: 19.66\t TAL: 13.31\t elapsed 0.03 s.\nEpisode: 13\t RWD: 27.00\t TCL: 25.42\t TAL: 17.51\t elapsed 0.04 s.\nEpisode: 14\t RWD: 22.00\t TCL: 20.48\t TAL: 13.39\t elapsed 0.04 s.\nEpisode: 15\t RWD: 13.00\t TCL: 11.29\t TAL: 8.36\t elapsed 0.02 s.\nEpisode: 16\t RWD: 11.00\t TCL: 9.24\t TAL: 6.26\t elapsed 0.02 s.\nEpisode: 17\t RWD: 11.00\t TCL: 9.29\t TAL: 6.04\t elapsed 0.02 s.\nEpisode: 18\t RWD: 19.00\t TCL: 16.68\t TAL: 12.01\t elapsed 0.03 s.\nEpisode: 19\t RWD: 26.00\t TCL: 24.26\t TAL: 16.35\t elapsed 0.04 s.\nEpisode: 20\t RWD: 36.00\t TCL: 33.54\t TAL: 21.62\t elapsed 0.06 s.\nEpisode: 21\t RWD: 44.00\t TCL: 40.86\t TAL: 28.03\t elapsed 0.07 s.\nEpisode: 22\t RWD: 65.00\t TCL: 63.65\t TAL: 40.22\t elapsed 0.11 s.\nEpisode: 23\t RWD: 38.00\t TCL: 35.06\t TAL: 23.90\t elapsed 0.08 s.\nEpisode: 24\t RWD: 33.00\t TCL: 30.00\t TAL: 19.27\t elapsed 0.06 s.\nEpisode: 25\t RWD: 38.00\t TCL: 34.82\t TAL: 21.21\t elapsed 0.07 s.\nEpisode: 26\t RWD: 33.00\t TCL: 29.86\t TAL: 19.35\t elapsed 0.05 s.\nEpisode: 27\t RWD: 43.00\t TCL: 39.27\t TAL: 23.96\t elapsed 0.07 s.\nEpisode: 28\t RWD: 26.00\t TCL: 22.79\t TAL: 13.56\t elapsed 0.04 s.\nEpisode: 29\t RWD: 28.00\t TCL: 24.33\t TAL: 15.08\t elapsed 0.05 s.\nEpisode: 30\t RWD: 29.00\t TCL: 24.99\t TAL: 14.79\t elapsed 0.05 s.\nEpisode: 31\t RWD: 24.00\t TCL: 20.06\t TAL: 11.43\t elapsed 0.04 s.\nEpisode: 32\t RWD: 31.00\t TCL: 27.37\t TAL: 16.32\t elapsed 0.06 s.\nEpisode: 33\t RWD: 33.00\t TCL: 28.30\t TAL: 15.86\t elapsed 0.06 s.\nEpisode: 34\t RWD: 59.00\t TCL: 52.31\t TAL: 31.16\t elapsed 0.10 s.\nEpisode: 35\t RWD: 59.00\t TCL: 50.68\t TAL: 28.95\t elapsed 0.12 s.\nEpisode: 36\t RWD: 84.00\t TCL: 90.55\t TAL: 43.04\t elapsed 0.17 s.\nEpisode: 37\t RWD: 76.00\t TCL: 66.69\t TAL: 38.05\t elapsed 0.15 s.\nEpisode: 38\t RWD: 27.00\t TCL: 21.21\t TAL: 14.50\t elapsed 0.05 s.\nEpisode: 39\t RWD: 48.00\t TCL: 53.18\t TAL: 22.76\t elapsed 0.08 s.\nEpisode: 40\t RWD: 47.00\t TCL: 40.25\t TAL: 25.29\t elapsed 0.09 s.\nEpisode: 41\t RWD: 43.00\t TCL: 35.80\t TAL: 21.89\t elapsed 0.08 s.\nEpisode: 42\t RWD: 52.00\t TCL: 44.13\t TAL: 24.52\t elapsed 0.08 s.\nEpisode: 43\t RWD: 120.00\t TCL: 111.33\t TAL: 50.26\t elapsed 0.19 s.\nEpisode: 44\t RWD: 92.00\t TCL: 83.30\t TAL: 39.07\t elapsed 0.15 s.\nEpisode: 45\t RWD: 27.00\t TCL: 20.78\t TAL: 12.39\t elapsed 0.05 s.\nEpisode: 46\t RWD: 33.00\t TCL: 25.81\t TAL: 10.76\t elapsed 0.07 s.\nEpisode: 47\t RWD: 74.00\t TCL: 62.54\t TAL: 28.01\t elapsed 0.12 s.\nEpisode: 48\t RWD: 89.00\t TCL: 75.60\t TAL: 29.39\t elapsed 0.15 s.\nEpisode: 49\t RWD: 41.00\t TCL: 48.72\t TAL: 14.06\t elapsed 0.07 s.\nEpisode: 50\t RWD: 82.00\t TCL: 80.45\t TAL: 23.12\t elapsed 0.12 s.\nEpisode: 51\t RWD: 52.00\t TCL: 55.11\t TAL: 15.27\t elapsed 0.09 s.\nEpisode: 52\t RWD: 23.00\t TCL: 23.32\t TAL: 5.20\t elapsed 0.04 s.\nEpisode: 53\t RWD: 46.00\t TCL: 45.35\t TAL: 18.15\t elapsed 0.07 s.\nEpisode: 54\t RWD: 48.00\t TCL: 43.68\t TAL: 12.51\t elapsed 0.08 s.\nEpisode: 55\t RWD: 34.00\t TCL: 28.94\t TAL: 7.06\t elapsed 0.06 s.\nEpisode: 56\t RWD: 37.00\t TCL: 31.75\t TAL: 9.33\t elapsed 0.06 s.\nEpisode: 57\t RWD: 87.00\t TCL: 78.91\t TAL: 23.83\t elapsed 0.17 s.\nEpisode: 58\t RWD: 103.00\t TCL: 95.26\t TAL: 25.47\t elapsed 0.18 s.\nEpisode: 59\t RWD: 60.00\t TCL: 51.39\t TAL: 14.31\t elapsed 0.13 s.\nEpisode: 60\t RWD: 95.00\t TCL: 94.73\t TAL: 29.38\t elapsed 0.16 s.\nEpisode: 61\t RWD: 60.00\t TCL: 48.45\t TAL: 17.06\t elapsed 0.11 s.\nEpisode: 62\t RWD: 61.00\t TCL: 48.42\t TAL: 14.98\t elapsed 0.11 s.\nEpisode: 63\t RWD: 57.00\t TCL: 46.07\t TAL: 11.66\t elapsed 0.09 s.\nEpisode: 64\t RWD: 63.00\t TCL: 49.90\t TAL: 14.97\t elapsed 0.12 s.\nEpisode: 65\t RWD: 78.00\t TCL: 63.44\t TAL: 19.27\t elapsed 0.13 s.\nEpisode: 66\t RWD: 135.00\t TCL: 110.77\t TAL: 29.99\t elapsed 0.22 s.\nEpisode: 67\t RWD: 53.00\t TCL: 37.04\t TAL: 9.71\t elapsed 0.08 s.\nEpisode: 68\t RWD: 75.00\t TCL: 56.66\t TAL: 14.02\t elapsed 0.14 s.\nEpisode: 69\t RWD: 52.00\t TCL: 38.34\t TAL: 11.71\t elapsed 0.10 s.\nEpisode: 70\t RWD: 41.00\t TCL: 33.50\t TAL: 7.71\t elapsed 0.07 s.\nEpisode: 71\t RWD: 53.00\t TCL: 37.69\t TAL: 7.08\t elapsed 0.10 s.\nEpisode: 72\t RWD: 39.00\t TCL: 27.15\t TAL: 12.21\t elapsed 0.07 s.\nEpisode: 73\t RWD: 60.00\t TCL: 43.59\t TAL: 7.78\t elapsed 0.10 s.\nEpisode: 74\t RWD: 43.00\t TCL: 28.22\t TAL: 6.89\t elapsed 0.08 s.\nEpisode: 75\t RWD: 35.00\t TCL: 23.09\t TAL: 5.23\t elapsed 0.07 s.\nEpisode: 76\t RWD: 44.00\t TCL: 29.57\t TAL: 9.67\t elapsed 0.08 s.\nEpisode: 77\t RWD: 34.00\t TCL: 21.32\t TAL: 4.88\t elapsed 0.06 s.\nEpisode: 78\t RWD: 49.00\t TCL: 37.20\t TAL: 8.70\t elapsed 0.09 s.\nEpisode: 79\t RWD: 29.00\t TCL: 17.40\t TAL: 3.31\t elapsed 0.05 s.\nEpisode: 80\t RWD: 55.00\t TCL: 37.49\t TAL: 8.96\t elapsed 0.10 s.\nEpisode: 81\t RWD: 30.00\t TCL: 15.97\t TAL: 2.35\t elapsed 0.05 s.\nEpisode: 82\t RWD: 33.00\t TCL: 18.76\t TAL: 2.25\t elapsed 0.06 s.\nEpisode: 83\t RWD: 37.00\t TCL: 20.27\t TAL: 5.40\t elapsed 0.06 s.\nEpisode: 84\t RWD: 39.00\t TCL: 26.67\t TAL: 4.18\t elapsed 0.08 s.\nEpisode: 85\t RWD: 44.00\t TCL: 28.80\t TAL: 8.42\t elapsed 0.07 s.\nEpisode: 86\t RWD: 37.00\t TCL: 22.33\t TAL: 3.78\t elapsed 0.06 s.\nEpisode: 87\t RWD: 43.00\t TCL: 23.50\t TAL: 3.70\t elapsed 0.08 s.\nEpisode: 88\t RWD: 78.00\t TCL: 53.57\t TAL: 10.39\t elapsed 0.14 s.\nEpisode: 89\t RWD: 103.00\t TCL: 67.99\t TAL: 16.97\t elapsed 0.19 s.\nEpisode: 90\t RWD: 75.00\t TCL: 43.72\t TAL: 12.52\t elapsed 0.14 s.\nEpisode: 91\t RWD: 46.00\t TCL: 33.18\t TAL: 7.49\t elapsed 0.08 s.\nEpisode: 92\t RWD: 37.00\t TCL: 16.09\t TAL: 2.61\t elapsed 0.07 s.\nEpisode: 93\t RWD: 46.00\t TCL: 22.51\t TAL: 4.34\t elapsed 0.08 s.\nEpisode: 94\t RWD: 41.00\t TCL: 16.87\t TAL: 4.78\t elapsed 0.08 s.\nEpisode: 95\t RWD: 41.00\t TCL: 16.35\t TAL: 7.49\t elapsed 0.08 s.\nEpisode: 96\t RWD: 33.00\t TCL: 10.67\t TAL: 2.43\t elapsed 0.05 s.\nEpisode: 97\t RWD: 55.00\t TCL: 37.62\t TAL: 8.69\t elapsed 0.10 s.\nEpisode: 98\t RWD: 35.00\t TCL: 13.95\t TAL: 6.83\t elapsed 0.06 s.\nEpisode: 99\t RWD: 41.00\t TCL: 15.23\t TAL: 6.47\t elapsed 0.07 s.\nEpisode: 100\t RWD: 53.00\t TCL: 26.10\t TAL: 9.49\t elapsed 0.10 s.\nEpisode: 101\t RWD: 40.00\t TCL: 13.53\t TAL: 5.00\t elapsed 0.08 s.\nEpisode: 102\t RWD: 42.00\t TCL: 15.18\t TAL: 3.61\t elapsed 0.08 s.\nEpisode: 103\t RWD: 61.00\t TCL: 25.32\t TAL: 4.51\t elapsed 0.12 s.\nEpisode: 104\t RWD: 35.00\t TCL: 7.86\t TAL: 2.51\t elapsed 0.06 s.\nEpisode: 105\t RWD: 32.00\t TCL: 6.16\t TAL: 1.19\t elapsed 0.06 s.\nEpisode: 106\t RWD: 54.00\t TCL: 19.00\t TAL: 4.62\t elapsed 0.09 s.\nEpisode: 107\t RWD: 46.00\t TCL: 12.33\t TAL: 2.89\t elapsed 0.09 s.\nEpisode: 108\t RWD: 53.00\t TCL: 23.10\t TAL: 3.97\t elapsed 0.09 s.\nEpisode: 109\t RWD: 62.00\t TCL: 23.65\t TAL: 4.84\t elapsed 0.12 s.\nEpisode: 110\t RWD: 35.00\t TCL: 5.72\t TAL: 2.66\t elapsed 0.06 s.\nEpisode: 111\t RWD: 50.00\t TCL: 22.67\t TAL: 6.18\t elapsed 0.08 s.\nEpisode: 112\t RWD: 43.00\t TCL: 13.32\t TAL: 3.64\t elapsed 0.08 s.\nEpisode: 113\t RWD: 33.00\t TCL: 7.06\t TAL: 4.38\t elapsed 0.06 s.\nEpisode: 114\t RWD: 66.00\t TCL: 25.98\t TAL: 6.25\t elapsed 0.12 s.\nEpisode: 115\t RWD: 44.00\t TCL: 13.84\t TAL: 3.02\t elapsed 0.08 s.\nEpisode: 116\t RWD: 73.00\t TCL: 29.40\t TAL: 5.08\t elapsed 0.13 s.\nEpisode: 117\t RWD: 46.00\t TCL: 8.21\t TAL: 2.53\t elapsed 0.08 s.\nEpisode: 118\t RWD: 56.00\t TCL: 12.44\t TAL: 3.46\t elapsed 0.10 s.\nEpisode: 119\t RWD: 42.00\t TCL: 5.27\t TAL: 2.09\t elapsed 0.07 s.\nEpisode: 120\t RWD: 57.00\t TCL: 10.74\t TAL: 4.27\t elapsed 0.11 s.\nEpisode: 121\t RWD: 154.00\t TCL: 58.13\t TAL: 11.46\t elapsed 0.27 s.\nEpisode: 122\t RWD: 63.00\t TCL: 11.35\t TAL: 2.89\t elapsed 0.11 s.\nEpisode: 123\t RWD: 95.00\t TCL: 24.03\t TAL: 2.67\t elapsed 0.17 s.\nEpisode: 124\t RWD: 87.00\t TCL: 29.01\t TAL: 6.01\t elapsed 0.15 s.\nEpisode: 125\t RWD: 217.00\t TCL: 97.72\t TAL: 28.84\t elapsed 0.38 s.\nEpisode: 126\t RWD: 212.00\t TCL: 87.51\t TAL: 11.65\t elapsed 0.37 s.\nEpisode: 127\t RWD: 177.00\t TCL: 330.86\t TAL: 1.19\t elapsed 0.32 s.\nEpisode: 128\t RWD: 131.00\t TCL: 77.20\t TAL: 10.21\t elapsed 0.22 s.\nEpisode: 129\t RWD: 278.00\t TCL: 100.94\t TAL: 28.03\t elapsed 0.49 s.\nEpisode: 130\t RWD: 156.00\t TCL: 26.27\t TAL: 6.43\t elapsed 0.26 s.\nEpisode: 131\t RWD: 151.00\t TCL: 22.77\t TAL: 2.40\t elapsed 0.25 s.\nEpisode: 132\t RWD: 126.00\t TCL: 23.25\t TAL: 2.31\t elapsed 0.21 s.\nEpisode: 133\t RWD: 124.00\t TCL: 17.85\t TAL: 0.74\t elapsed 0.23 s.\nEpisode: 134\t RWD: 122.00\t TCL: 14.40\t TAL: -1.81\t elapsed 0.21 s.\nEpisode: 135\t RWD: 162.00\t TCL: 16.00\t TAL: 8.50\t elapsed 0.30 s.\nEpisode: 136\t RWD: 157.00\t TCL: 12.44\t TAL: 4.47\t elapsed 0.27 s.\nEpisode: 137\t RWD: 171.00\t TCL: 14.92\t TAL: 10.88\t elapsed 0.28 s.\nEpisode: 138\t RWD: 120.00\t TCL: 24.79\t TAL: 2.81\t elapsed 0.19 s.\nEpisode: 139\t RWD: 158.00\t TCL: 17.50\t TAL: 2.64\t elapsed 0.27 s.\nEpisode: 140\t RWD: 198.00\t TCL: 23.57\t TAL: 6.50\t elapsed 0.35 s.\nEpisode: 141\t RWD: 165.00\t TCL: 37.76\t TAL: 5.53\t elapsed 0.30 s.\nEpisode: 142\t RWD: 172.00\t TCL: 38.87\t TAL: 12.91\t elapsed 0.30 s.\nEpisode: 143\t RWD: 117.00\t TCL: 24.03\t TAL: -0.47\t elapsed 0.20 s.\nEpisode: 144\t RWD: 117.00\t TCL: 9.87\t TAL: 0.26\t elapsed 0.19 s.\nEpisode: 145\t RWD: 134.00\t TCL: 8.32\t TAL: 0.81\t elapsed 0.22 s.\nEpisode: 146\t RWD: 151.00\t TCL: 8.52\t TAL: 1.17\t elapsed 0.25 s.\nEpisode: 147\t RWD: 181.00\t TCL: 9.91\t TAL: 3.37\t elapsed 0.33 s.\nEpisode: 148\t RWD: 136.00\t TCL: 6.94\t TAL: -0.95\t elapsed 0.24 s.\nEpisode: 149\t RWD: 138.00\t TCL: 10.59\t TAL: 1.73\t elapsed 0.25 s.\nEpisode: 150\t RWD: 129.00\t TCL: 5.84\t TAL: -0.45\t elapsed 0.23 s.\nEpisode: 151\t RWD: 132.00\t TCL: 3.47\t TAL: 0.03\t elapsed 0.25 s.\nEpisode: 152\t RWD: 145.00\t TCL: 3.77\t TAL: 2.06\t elapsed 0.26 s.\nEpisode: 153\t RWD: 134.00\t TCL: 10.63\t TAL: 6.98\t elapsed 0.25 s.\nEpisode: 154\t RWD: 325.00\t TCL: 41.39\t TAL: 18.27\t elapsed 0.60 s.\nEpisode: 155\t RWD: 141.00\t TCL: 35.99\t TAL: 6.87\t elapsed 0.26 s.\nEpisode: 156\t RWD: 51.00\t TCL: 1950.92\t TAL: -2.25\t elapsed 0.09 s.\nEpisode: 157\t RWD: 22.00\t TCL: 2796.25\t TAL: -6.50\t elapsed 0.04 s.\nEpisode: 158\t RWD: 16.00\t TCL: 1934.40\t TAL: -3.30\t elapsed 0.03 s.\nEpisode: 159\t RWD: 17.00\t TCL: 1446.00\t TAL: -5.24\t elapsed 0.03 s.\nEpisode: 160\t RWD: 32.00\t TCL: 439.51\t TAL: 9.41\t elapsed 0.06 s.\nEpisode: 161\t RWD: 60.00\t TCL: 448.87\t TAL: -37.41\t elapsed 0.11 s.\nEpisode: 162\t RWD: 11.00\t TCL: 865.05\t TAL: 3.88\t elapsed 0.02 s.\nEpisode: 163\t RWD: 9.00\t TCL: 572.68\t TAL: 8.04\t elapsed 0.01 s.\nEpisode: 164\t RWD: 8.00\t TCL: 170.01\t TAL: -31.54\t elapsed 0.01 s.\nEpisode: 165\t RWD: 10.00\t TCL: 131.88\t TAL: -0.85\t elapsed 0.02 s.\nEpisode: 166\t RWD: 11.00\t TCL: 164.10\t TAL: -0.67\t elapsed 0.02 s.\nEpisode: 167\t RWD: 10.00\t TCL: 98.47\t TAL: -0.65\t elapsed 0.02 s.\nEpisode: 168\t RWD: 9.00\t TCL: 106.84\t TAL: -0.75\t elapsed 0.02 s.\nEpisode: 169\t RWD: 8.00\t TCL: 118.62\t TAL: -0.75\t elapsed 0.01 s.\nEpisode: 170\t RWD: 9.00\t TCL: 81.75\t TAL: -0.74\t elapsed 0.02 s.\nEpisode: 171\t RWD: 10.00\t TCL: 82.82\t TAL: -0.71\t elapsed 0.02 s.\nEpisode: 172\t RWD: 10.00\t TCL: 68.96\t TAL: -0.78\t elapsed 0.02 s.\nEpisode: 173\t RWD: 10.00\t TCL: 60.82\t TAL: -0.83\t elapsed 0.02 s.\nEpisode: 174\t RWD: 9.00\t TCL: 89.61\t TAL: -1.07\t elapsed 0.02 s.\nEpisode: 175\t RWD: 10.00\t TCL: 147.74\t TAL: 10.84\t elapsed 0.02 s.\nEpisode: 176\t RWD: 10.00\t TCL: 58.33\t TAL: -1.49\t elapsed 0.02 s.\nEpisode: 177\t RWD: 11.00\t TCL: 65.20\t TAL: -1.94\t elapsed 0.02 s.\nEpisode: 178\t RWD: 10.00\t TCL: 244.50\t TAL: 10.16\t elapsed 0.02 s.\nEpisode: 179\t RWD: 10.00\t TCL: 99.54\t TAL: -0.91\t elapsed 0.02 s.\nEpisode: 180\t RWD: 10.00\t TCL: 61.11\t TAL: -7.26\t elapsed 0.02 s.\nEpisode: 181\t RWD: 338.00\t TCL: 2297.66\t TAL: 69.71\t elapsed 0.61 s.\nEpisode: 182\t RWD: 120.00\t TCL: 225.62\t TAL: 34.88\t elapsed 0.22 s.\nEpisode: 183\t RWD: 101.00\t TCL: 150.75\t TAL: 37.88\t elapsed 0.19 s.\nEpisode: 184\t RWD: 117.00\t TCL: 121.48\t TAL: 29.93\t elapsed 0.21 s.\nEpisode: 185\t RWD: 91.00\t TCL: 69.12\t TAL: 21.51\t elapsed 0.15 s.\nEpisode: 186\t RWD: 210.00\t TCL: 204.67\t TAL: 76.08\t elapsed 0.38 s.\nEpisode: 187\t RWD: 204.00\t TCL: 181.54\t TAL: 71.72\t elapsed 0.36 s.\nEpisode: 188\t RWD: 172.00\t TCL: 129.19\t TAL: 46.92\t elapsed 0.31 s.\nEpisode: 189\t RWD: 119.00\t TCL: 84.12\t TAL: 23.88\t elapsed 0.20 s.\nEpisode: 190\t RWD: 148.00\t TCL: 101.10\t TAL: 38.67\t elapsed 0.27 s.\nEpisode: 191\t RWD: 269.00\t TCL: 211.14\t TAL: 67.07\t elapsed 0.47 s.\nEpisode: 192\t RWD: 262.00\t TCL: 970.18\t TAL: 49.28\t elapsed 0.51 s.\nEpisode: 193\t RWD: 59.00\t TCL: 211.26\t TAL: 6.12\t elapsed 0.10 s.\nEpisode: 194\t RWD: 118.00\t TCL: 74.08\t TAL: 23.70\t elapsed 0.22 s.\nEpisode: 195\t RWD: 500.00\t TCL: 552.45\t TAL: 64.54\t elapsed 0.98 s.\nEpisode: 196\t RWD: 309.00\t TCL: 207.39\t TAL: 40.39\t elapsed 0.54 s.\nEpisode: 197\t RWD: 143.00\t TCL: 87.28\t TAL: 22.55\t elapsed 0.26 s.\nEpisode: 198\t RWD: 332.00\t TCL: 219.07\t TAL: 49.98\t elapsed 0.58 s.\nEpisode: 199\t RWD: 306.00\t TCL: 185.11\t TAL: 45.01\t elapsed 0.53 s.\nEpisode: 200\t RWD: 189.00\t TCL: 143.77\t TAL: 25.73\t elapsed 0.39 s.\nEpisode: 201\t RWD: 500.00\t TCL: 726.25\t TAL: 62.93\t elapsed 0.92 s.\nEpisode: 202\t RWD: 245.00\t TCL: 181.43\t TAL: 21.41\t elapsed 0.44 s.\nEpisode: 203\t RWD: 216.00\t TCL: 162.43\t TAL: 25.36\t elapsed 0.38 s.\nEpisode: 204\t RWD: 334.00\t TCL: 244.47\t TAL: 27.16\t elapsed 0.63 s.\nEpisode: 205\t RWD: 386.00\t TCL: 336.15\t TAL: 39.66\t elapsed 0.76 s.\nEpisode: 206\t RWD: 500.00\t TCL: 523.30\t TAL: 33.61\t elapsed 0.89 s.\nEpisode: 207\t RWD: 500.00\t TCL: 384.24\t TAL: 33.12\t elapsed 0.91 s.\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b53108577212>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0madam_critic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mcritic_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0madam_critic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mactor_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0madvantage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mbias_correction1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "episode_rewards, TAL, TCL = [], [], []\n",
    "\n",
    "for i in range(500):\n",
    "    done = False\n",
    "    total_reward, total_critic_loss, total_actor_loss = 0, 0, 0\n",
    "    \n",
    "    state = env.reset()\n",
    "\n",
    "    tt = time.time()\n",
    "    while not done:\n",
    "        probs = actor(t(state))\n",
    "        dist = torch.distributions.Categorical(probs=probs)\n",
    "        action = dist.sample()\n",
    "        \n",
    "        next_state, reward, done, info = env.step(action.detach().data.numpy())\n",
    "        \n",
    "        # see the cell above for explanation\n",
    "        advantage = reward + (1-done)*gamma*critic(t(next_state)) - critic(t(state))\n",
    "        \n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "\n",
    "        critic_loss = advantage.pow(2).mean()\n",
    "        total_critic_loss += critic_loss.item()\n",
    "        adam_critic.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        adam_critic.step()\n",
    "\n",
    "        actor_loss = -dist.log_prob(action)*advantage.detach()\n",
    "        total_actor_loss += actor_loss.item()\n",
    "        adam_actor.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        adam_actor.step()\n",
    "    \n",
    "    TAL.append(total_actor_loss)\n",
    "    TCL.append(total_critic_loss)\n",
    "    print('Episode: {}\\t RWD: {:.2f}\\t TCL: {:.2f}\\t TAL: {:.2f}\\t elapsed {:.2f} s.'.format(i,\n",
    "                                                                         total_reward,\n",
    "                                                                         total_critic_loss, \n",
    "                                                                         total_actor_loss,\n",
    "                                                                         time.time()-tt))\n",
    "    episode_rewards.append(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.scatter(np.arange(len(episode_rewards)), episode_rewards, s=2)\n",
    "plt.title(\"Total reward per episode (online)\")\n",
    "plt.ylabel(\"reward\")\n",
    "plt.xlabel(\"episode\")\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(TAL)\n",
    "plt.title('Total Actor Loss')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(TCL)\n",
    "plt.title('Total Critic Loss')\n",
    "torch.save(actor.state_dict(), './actor_{}.pth'.format('LunarLander'))\n",
    "torch.save(critic.state_dict(), './critic_{}.pth'.format('LunarLander'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}