{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import transform as im_tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# make sure you don't hog all the video memory\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import gym\n",
    "import pickle\n",
    "\n",
    "def RGB2gray(img):\n",
    "    R, G, B = img[:, :, 0], img[:, :, 1], img[:, :, 2]\n",
    "    return 1/3 * R + 1/3 * G + 1/3 * B\n",
    "\n",
    "def prepro(o, image_size=[80, 80]):\n",
    "    y = 0.2126 * o[:, :, 0] + 0.7152 * o[:, :, 1] + 0.0722 * o[:, :, 2]\n",
    "    y = y.astype(np.uint8)\n",
    "    resized = im_tf.resize(y, image_size, mode='constant')\n",
    "    return resized\n",
    "#     return np.expand_dims(resized.astype(np.float32), axis=2).ravel()\n",
    "\n",
    "def preprocess(I):\n",
    "    \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
    "    I = I[35:195] # crop\n",
    "    I = I[::2,::2,0] # downsample by factor of 2\n",
    "    I[I == 144] = 0 # erase background (background type 1)\n",
    "    I[I == 109] = 0 # erase background (background type 2)\n",
    "    I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "    return I.astype(np.float).ravel()\n",
    "\n",
    "class Agent_PG:\n",
    "    def __init__(self):\n",
    "        self.env = gym.make(\"Pong-v0\")\n",
    "        self.S = None\n",
    "        self.mean = 0.\n",
    "        self.std = 1.\n",
    "        self.nda = []\n",
    "        self.batch_size = 32\n",
    "        self.__init_game_setting()\n",
    "        self.brain = self.Net()\n",
    "        self.lrate = 0.001\n",
    "        \n",
    "    def __init_game_setting(self):\n",
    "        self.observation = self.env.reset()\n",
    "        \n",
    "    \n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            nn.Module.__init__(self)\n",
    "            self.conv1 = nn.Conv2d(1, 16, 8, stride=4)\n",
    "            self.conv2 = nn.Conv2d(16, 32, 4, stride=2)\n",
    "            self.fc1 = nn.Linear(2048, 128)\n",
    "            self.fc2 = nn.Linear(128, 2)\n",
    "            torch.nn.init.xavier_uniform_(self.conv1.weight)\n",
    "            torch.nn.init.xavier_uniform_(self.conv2.weight)\n",
    "            torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "            torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = x.view(-1,1,80,80)\n",
    "            x = self.conv1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.conv2(x)\n",
    "            x = F.relu(x)\n",
    "            x = x.view(-1, 2048)\n",
    "            x = self.fc1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.fc2(x)\n",
    "            x = F.softmax(x, dim=1)\n",
    "            return x\n",
    "\n",
    "        def update_parameters(self, lrate):\n",
    "            for f in self.parameters():\n",
    "                f.data.sub_(f.grad.data*lrate)\n",
    "        \n",
    "\n",
    "    def fit(self, S, A, discount_reward):\n",
    "        action_onehot = torch.tensor(to_categorical(A.reshape(-1), num_classes=2))\n",
    "        X_pt = torch.tensor(S.reshape(-1,80,80,1)).float()\n",
    "        pred = self.brain.forward(X_pt)\n",
    "        \n",
    "        objective = torch.sum(action_onehot*pred, dim=1)\n",
    "        objective = torch.log(objective)\n",
    "        objective = -objective * torch.tensor(discount_reward)\n",
    "        objective = torch.sum(objective)\n",
    "\n",
    "        self.brain.zero_grad()\n",
    "        objective.backward(retain_graph=True)\n",
    "        self.brain.update_parameters(self.lrate)\n",
    "        \n",
    "        return objective.detach().numpy()\n",
    "    \n",
    "    def run_episode(self,i):  ####### playing one episode\n",
    "        state = self.observation\n",
    "        done = False\n",
    "        episode_reward = 0.0\n",
    "        S = np.zeros([10000, 80, 80])\n",
    "        A = np.zeros([10000,])\n",
    "        R = np.zeros([10000,])\n",
    "        j = 0\n",
    "        while not done:\n",
    "            action = self.make_action(state, test=False)\n",
    "            state, reward, done, info = self.env.step(action)\n",
    "            episode_reward += reward\n",
    "            S[j] = self.S\n",
    "            A[j] = 0 if action == 2 else 1\n",
    "            R[j] = reward\n",
    "            j = j + 1\n",
    "        self.nda = sum(A)/j\n",
    "\n",
    "        def compute_discounted_R(R, discount_rate=.99):\n",
    "            discounted_r = np.zeros_like(R, dtype=np.float32)\n",
    "            running_add = 0\n",
    "            for t in reversed(range(R.shape[0])):\n",
    "                if R[t] != 0: running_add = 0\n",
    "                running_add = running_add * discount_rate + R[t]\n",
    "                discounted_r[t] = running_add\n",
    "            discounted_r = (discounted_r-discounted_r.mean()) / (discounted_r.std()+0.00001)\n",
    "            return discounted_r\n",
    "        RR = R[:j]\n",
    "        RR = compute_discounted_R(RR)\n",
    "        return S[:j], A[:j], RR-0.01, episode_reward\n",
    "#         return S[:j], A[:j], RR, episode_reward\n",
    "\n",
    "    def train(self, n_episodes):\n",
    "        reward_history = []\n",
    "        for i in range(n_episodes):\n",
    "            self.__init_game_setting()\n",
    "            S, A, discount_reward, episode_reward = self.run_episode(i)\n",
    "            loss = self.fit(S, A, discount_reward)\n",
    "\n",
    "            ########### print and save\n",
    "            print('Episode: {} \\t Reward {} \\t Mean action {:0.2f} \\t Frames {}'.format(i, episode_reward, np.mean(A), A.shape[0]))\n",
    "            with open(\"log_PG_PYTORCH.txt\", \"a\") as myfile:\n",
    "                myfile.write(\"episode \" + str(i) + \"\\t\" +\n",
    "                             \"loss \" + str(loss) + \"\\t\" +\n",
    "                             \" episode reward \" + str(episode_reward) + \"\\t\" +\n",
    "                             \" number of down act \" + str(self.nda) + \"\\t\" +\n",
    "                             \" game_len \" + str(len(discount_reward)) + \"\\t\" +\n",
    "                             \"\\n\")\n",
    "            reward_history.append(episode_reward)\n",
    "            torch.save(self.brain.state_dict(), 'checkpoint.pth')\n",
    "\n",
    "    def make_action(self, observation, test=True):\n",
    "        prev_observation = observation\n",
    "        observation = prepro(observation - self.observation)\n",
    "        \n",
    "        pi_action = self.brain.forward(torch.tensor(observation.reshape(1,80,80,1)).float())\n",
    "        pi_action = np.squeeze(pi_action.detach().numpy(), axis=0)\n",
    "\n",
    "        if test:\n",
    "            action = pi_action.argmax()\n",
    "        else:\n",
    "            action = np.random.choice(2, p=pi_action)\n",
    "        self.observation = prev_observation\n",
    "        self.S = observation\n",
    "        return 2 if action == 0 else 3\n",
    "\n",
    "agent = Agent_PG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(8, 8), stride=(4, 4))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(4, 4), stride=(2, 2))\n",
      "  (fc1): Linear(in_features=2048, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 \t Reward -17.0 \t Mean action 0.47 \t Frames 1686\n",
      "Episode: 1 \t Reward -21.0 \t Mean action 0.49 \t Frames 1502\n",
      "Episode: 2 \t Reward -21.0 \t Mean action 0.67 \t Frames 1273\n",
      "Episode: 3 \t Reward -21.0 \t Mean action 0.60 \t Frames 1196\n",
      "Episode: 4 \t Reward -21.0 \t Mean action 0.51 \t Frames 1182\n",
      "Episode: 5 \t Reward -21.0 \t Mean action 0.59 \t Frames 1348\n",
      "Episode: 6 \t Reward -21.0 \t Mean action 0.60 \t Frames 1194\n"
     ]
    }
   ],
   "source": [
    "print(agent.brain)\n",
    "n_episodes = 15000\n",
    "agent.train(n_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.0986123, 0.6931472], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val = K.placeholder(shape=(None, 2))\n",
    "fn = K.function(inputs = [val], outputs=[K.log(val)])\n",
    "fn([np.array([3,2])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testnet(nn.Module):\n",
    "    def forward(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer conv1.weight \t\t shape torch.Size([16, 1, 8, 8])\n",
      "Layer conv1.bias \t\t shape torch.Size([16])\n",
      "Layer conv2.weight \t\t shape torch.Size([32, 16, 4, 4])\n",
      "Layer conv2.bias \t\t shape torch.Size([32])\n",
      "Layer fc1.weight \t\t shape torch.Size([128, 2048])\n",
      "Layer fc1.bias \t\t shape torch.Size([128])\n",
      "Layer fc2.weight \t\t shape torch.Size([2, 128])\n",
      "Layer fc2.bias \t\t shape torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "w = []\n",
    "for k, v in agent.brain.state_dict().items():\n",
    "    print(\"Layer {} \\t\\t shape {}\".format(k,v.size()))\n",
    "    w.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 80, 80, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 19, 19, 16)        1040      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 8, 8, 32)          8224      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               262272    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 271,794\n",
      "Trainable params: 271,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Input, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Conv2D, Flatten, Reshape, Lambda, MaxPooling2D, BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Reshape((80, 80, 1), input_shape=(6400,)))\n",
    "model.add(Conv2D(16, (8, 8), strides = (4, 4), activation='relu', kernel_initializer='lecun_uniform'))\n",
    "model.add(Conv2D(32, (4, 4), strides = (2, 2), activation='relu', kernel_initializer='lecun_uniform'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='lecun_uniform'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model = model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in model.layers:\n",
    "    print(len(i.get_weights()))\n",
    "#     print(i.get_weights().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
